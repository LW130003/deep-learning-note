Understanding Mutual Information and its Use in InfoGAN

Interpretable variables are useful in generative models. GAN are generative models that are flexible in their input. The InfoGAN ties the output of the generator to a component of its input called the latnet codes. By forcing the output of the generator to a component of its input called the latent codes. By forcing the output to be tied to this input component, we can control some properties of the output representation. It is notoriously difficult to find the Nash equilibrium when jointly training the discriminator and the generator ina GAN. We uncover some successful and unsuccessful configurations for generating images using InfoGAN

-------------------------------------
Introduction

The goal of a generative model is to approximate the distribution of some real data. In the case of labeled data and supervised discriminative learning, it is easy to approximate the distirbution of labels using a classifier.

